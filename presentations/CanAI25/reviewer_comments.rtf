{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww28820\viewh17760\viewkind0
\deftab560
\pard\pardeftab560\slleading20\partightenfactor0

\f0\fs26 \cf0 We are pleased to inform you that your paper submission "Automatic Extraction of Performance Metrics from the Scientific Literature with an Extract-and-Verify Loop" to the LLM Workshop has been accepted for an oral presentation. A 10-minute speaking slot (plus 2 minutes for questions) will be assigned; the final schedule will be circulated shortly.\
\
The workshop is non-archival, so you remain free to submit the work to another venue.\
\
If you have any questions, please reach out to us.\
\
Sincerely,\
The LLM Workshop Committee\
\pard\pardeftab560\slleading20\partightenfactor0
\cf0 \
Reviewer's comments:\
The paper offers a clear, reproducible pipeline that couples PDF chunking with a self-verification prompt loop, achieving slightly higher recall than the SCILEAD baseline while preserving perfect precision. Releasing the annotated corpus is valuable. However, the evaluation set is small and not held-out, so the reported 4-point recall gain may not be statistically robust. Extending the dataset and adding significance tests would strengthen the claims, but the current contribution is still a useful incremental step for automatic metric extraction.}